# üìú Enhanced Text Summarization Application

This project extends a modular text summarization pipeline using the **SAMSum** dataset. It includes hyperparameter tuning, visualization, fine-tuning, and a comparison between **BART** and **T5** models.

---

## üöÄ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/sahilshukla3003/Text-Summarization_Finetune.git
cd Text-Summarization_Finetune
```

### 2. Create and Activate Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Run the Application

```bash
python main.py
```

This will:

- Load the SAMSum test dataset.
- Perform hyperparameter tuning for BART and T5.
- Generate summaries for 10 samples per model.
- Fine-tune BART on 50 training samples.
- Evaluate summaries using ROUGE scores.
- Visualize score distributions.
- Save results, scores, and qualitative examples.

---

## üìÅ Project Structure

| File / Folder          | Description                                                 |
|------------------------|-------------------------------------------------------------|
| `data_loader.py`       | Loads and preprocesses the SAMSum dataset.                  |
| `model.py`             | Handles loading, inference, and fine-tuning for BART/T5.    |
| `pipeline.py`          | Orchestrates data flow and summarization.                   |
| `evaluator.py`         | Evaluates summaries and visualizes metrics.                 |
| `main.py`              | Main script to run the full pipeline.                       |
| `fineTune.py`          | Fine-tunes the model on SAMSum samples.                     |
| `test_fineTune.py`     | Tests the fine-tuned model and compares with pre-trained.   |
| `requirements.txt`     | List of required Python packages.                           |
| `insights.md`          | Documents findings, limitations, and enhancements.          |

---

## ‚öôÔ∏è Design Choices

- **Models**: Compared `facebook/bart-large-cnn` (strong abstractive performance) and `t5-small` (lightweight for experimentation).
- **Tuning**: Simple grid search over `num_beams` and `length_penalty` to optimize ROUGE-1.
- **Fine-Tuning**: Trained BART on 50 samples to demo dialogue-specific improvements.
- **Visualization**: Histogram of ROUGE scores to analyze output distribution.
- **Modularity**: Class-based structure allows reusability and clarity.

---

## üìä Outputs

| Output File                    | Description                                  |
|-------------------------------|----------------------------------------------|
| `summarization_results_*.json`| Summaries generated by each model.           |
| `rouge_scores_*.json`         | ROUGE-1/2/L scores per model.                |
| `qualitative_examples_*.json` | Selected dialogue-summary pairs.             |
| `*.png`                       | ROUGE score histograms.                      |
| `./fine_tuned_model/`         | Directory containing the fine-tuned BART.    |

